{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "def elapsed(sec):\n",
    "    if sec<60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec<(60*60):\n",
    "        return str(sec/60) + \" min\"\n",
    "    else:\n",
    "        return str(sec/(60*60)) + \" hr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = '/rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = 'sample.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    with open(file_name) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [content[i].split() for i in range(len(content))]\n",
    "    content = np.array(content)\n",
    "    content = np.reshape(content, [-1, ])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['long', 'ago', ',', 'the', 'mice', 'had', 'a', 'general', 'council',\n",
       "       'to', 'consider', 'what', 'measures', 'they', 'could', 'take', 'to',\n",
       "       'outwit', 'their', 'common', 'enemy', ',', 'the', 'cat', '.',\n",
       "       'some', 'said', 'this', ',', 'and', 'some', 'said', 'that', 'but',\n",
       "       'at', 'last', 'a', 'young', 'mouse', 'got', 'up', 'and', 'said',\n",
       "       'he', 'had', 'a', 'proposal', 'to', 'make', ',', 'which', 'he',\n",
       "       'thought', 'would', 'meet', 'the', 'case', '.', 'you', 'will',\n",
       "       'all', 'agree', ',', 'said', 'he', ',', 'that', 'our', 'chief',\n",
       "       'danger', 'consists', 'in', 'the', 'sly', 'and', 'treacherous',\n",
       "       'manner', 'in', 'which', 'the', 'enemy', 'approaches', 'us', '.',\n",
       "       'now', ',', 'if', 'we', 'could', 'receive', 'some', 'signal', 'of',\n",
       "       'her', 'approach', ',', 'we', 'could', 'easily', 'escape', 'from',\n",
       "       'her', '.', 'i', 'venture', ',', 'therefore', ',', 'to', 'propose',\n",
       "       'that', 'a', 'small', 'bell', 'be', 'procured', ',', 'and',\n",
       "       'attached', 'by', 'a', 'ribbon', 'round', 'the', 'neck', 'of',\n",
       "       'the', 'cat', '.', 'by', 'this', 'means', 'we', 'should', 'always',\n",
       "       'know', 'when', 'she', 'was', 'about', ',', 'and', 'could',\n",
       "       'easily', 'retire', 'while', 'she', 'was', 'in', 'the',\n",
       "       'neighbourhood', '.', 'this', 'proposal', 'met', 'with', 'general',\n",
       "       'applause', ',', 'until', 'an', 'old', 'mouse', 'got', 'up', 'and',\n",
       "       'said', 'that', 'is', 'all', 'very', 'well', ',', 'but', 'who',\n",
       "       'is', 'to', 'bell', 'the', 'cat', '?', 'the', 'mice', 'looked',\n",
       "       'at', 'one', 'another', 'and', 'nobody', 'spoke', '.', 'then',\n",
       "       'the', 'old', 'mouse', 'said', 'it', 'is', 'easy', 'to', 'propose',\n",
       "       'impossible', 'remedies', '.'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "dictionary, reverse_dictionary = build_dataset(train_data)\n",
    "vocab_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "display_step = 1000\n",
    "n_input = 3\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x,n_input,1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # Average Accuracy= 95.20% at 50k iter\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#Initialize variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 1000, Average Loss= 4.443420, Average Accuracy= 3.10%\n",
      "['the', 'old', 'mouse'] - [said] vs [means]\n",
      "Iter= 2000, Average Loss= 2.751008, Average Accuracy= 24.50%\n",
      "['and', 'nobody', 'spoke'] - [.] vs [this]\n",
      "Iter= 3000, Average Loss= 2.476694, Average Accuracy= 32.00%\n",
      "['is', 'all', 'very'] - [well] vs [with]\n",
      "Iter= 4000, Average Loss= 2.060927, Average Accuracy= 47.50%\n",
      "['old', 'mouse', 'got'] - [up] vs [up]\n",
      "Iter= 5000, Average Loss= 1.798270, Average Accuracy= 50.60%\n",
      "['this', 'proposal', 'met'] - [with] vs [from]\n",
      "Iter= 6000, Average Loss= 1.567409, Average Accuracy= 55.40%\n",
      "['a', 'ribbon', 'round'] - [the] vs [the]\n",
      "Iter= 7000, Average Loss= 1.398148, Average Accuracy= 61.20%\n",
      "['receive', 'some', 'signal'] - [of] vs [of]\n",
      "Iter= 8000, Average Loss= 1.432168, Average Accuracy= 61.30%\n",
      "['treacherous', 'manner', 'in'] - [which] vs [the]\n",
      "Iter= 9000, Average Loss= 1.304113, Average Accuracy= 64.00%\n",
      "['agree', ',', 'said'] - [he] vs [he]\n",
      "Iter= 10000, Average Loss= 1.078658, Average Accuracy= 72.70%\n",
      "['meet', 'the', 'case'] - [.] vs [.]\n",
      "Iter= 11000, Average Loss= 0.945713, Average Accuracy= 77.50%\n",
      "['had', 'a', 'proposal'] - [to] vs [escape]\n",
      "Iter= 12000, Average Loss= 0.867566, Average Accuracy= 77.40%\n",
      "['mice', 'had', 'a'] - [general] vs [general]\n",
      "Iter= 13000, Average Loss= 0.917716, Average Accuracy= 77.30%\n",
      "['and', 'nobody', 'spoke'] - [.] vs [.]\n",
      "Iter= 14000, Average Loss= 0.921360, Average Accuracy= 76.50%\n",
      "['but', 'who', 'is'] - [to] vs [to]\n",
      "Iter= 15000, Average Loss= 0.749969, Average Accuracy= 81.00%\n",
      "['general', 'applause', ','] - [until] vs [until]\n",
      "Iter= 16000, Average Loss= 0.720596, Average Accuracy= 81.50%\n",
      "['she', 'was', 'in'] - [the] vs [the]\n",
      "Iter= 17000, Average Loss= 0.676566, Average Accuracy= 82.10%\n",
      "['we', 'should', 'always'] - [know] vs [know]\n",
      "Iter= 18000, Average Loss= 0.628798, Average Accuracy= 82.90%\n",
      "['round', 'the', 'neck'] - [of] vs [of]\n",
      "Iter= 19000, Average Loss= 0.503692, Average Accuracy= 86.70%\n",
      "['that', 'a', 'small'] - [bell] vs [bell]\n",
      "Iter= 20000, Average Loss= 0.629182, Average Accuracy= 84.30%\n",
      "['we', 'could', 'easily'] - [escape] vs [escape]\n",
      "Iter= 21000, Average Loss= 0.517517, Average Accuracy= 86.30%\n",
      "['manner', 'in', 'which'] - [the] vs [the]\n",
      "Iter= 22000, Average Loss= 0.522584, Average Accuracy= 85.60%\n",
      "['the', 'case', '.'] - [you] vs [you]\n",
      "Iter= 23000, Average Loss= 0.607453, Average Accuracy= 83.00%\n",
      "['that', 'but', 'at'] - [last] vs [last]\n",
      "Iter= 24000, Average Loss= 0.613965, Average Accuracy= 84.20%\n",
      "['council', 'to', 'consider'] - [what] vs [what]\n",
      "Iter= 25000, Average Loss= 0.483310, Average Accuracy= 85.90%\n",
      "['easy', 'to', 'propose'] - [impossible] vs [impossible]\n",
      "Iter= 26000, Average Loss= 0.637027, Average Accuracy= 82.40%\n",
      "['spoke', '.', 'then'] - [the] vs [the]\n",
      "Iter= 27000, Average Loss= 0.588953, Average Accuracy= 85.20%\n",
      "['one', 'another', 'and'] - [nobody] vs [nobody]\n",
      "Iter= 28000, Average Loss= 0.584245, Average Accuracy= 86.10%\n",
      "['the', 'cat', '?'] - [the] vs [the]\n",
      "Iter= 29000, Average Loss= 0.536894, Average Accuracy= 86.30%\n",
      "['is', 'to', 'bell'] - [the] vs [the]\n",
      "Iter= 30000, Average Loss= 0.491967, Average Accuracy= 88.50%\n",
      "['all', 'very', 'well'] - [,] vs [general]\n",
      "Iter= 31000, Average Loss= 0.484571, Average Accuracy= 86.70%\n",
      "['she', 'was', 'in'] - [the] vs [the]\n",
      "Iter= 32000, Average Loss= 0.559514, Average Accuracy= 87.10%\n",
      "['.', 'by', 'this'] - [means] vs [means]\n",
      "Iter= 33000, Average Loss= 0.629689, Average Accuracy= 84.80%\n",
      "['ribbon', 'round', 'the'] - [neck] vs [neck]\n",
      "Iter= 34000, Average Loss= 0.436198, Average Accuracy= 88.40%\n",
      "['from', 'her', '.'] - [i] vs [i]\n",
      "Iter= 35000, Average Loss= 0.599095, Average Accuracy= 86.70%\n",
      "['could', 'receive', 'some'] - [signal] vs [signal]\n",
      "Iter= 36000, Average Loss= 0.420870, Average Accuracy= 89.60%\n",
      "['the', 'sly', 'and'] - [treacherous] vs [treacherous]\n",
      "Iter= 37000, Average Loss= 0.512466, Average Accuracy= 87.80%\n",
      "['which', 'he', 'thought'] - [would] vs [would]\n",
      "Iter= 38000, Average Loss= 0.476439, Average Accuracy= 88.20%\n",
      "['had', 'a', 'proposal'] - [to] vs [to]\n",
      "Iter= 39000, Average Loss= 0.583078, Average Accuracy= 86.90%\n",
      "['but', 'at', 'last'] - [a] vs [a]\n",
      "Iter= 40000, Average Loss= 0.438008, Average Accuracy= 88.70%\n",
      "['to', 'outwit', 'their'] - [common] vs [measures]\n",
      "Iter= 41000, Average Loss= 0.527648, Average Accuracy= 87.20%\n",
      "['council', 'to', 'consider'] - [what] vs [what]\n",
      "Iter= 42000, Average Loss= 0.459210, Average Accuracy= 89.40%\n",
      "['the', 'mice', 'looked'] - [at] vs [us]\n",
      "Iter= 43000, Average Loss= 0.388628, Average Accuracy= 90.40%\n",
      "['an', 'old', 'mouse'] - [got] vs [got]\n",
      "Iter= 44000, Average Loss= 0.501943, Average Accuracy= 89.50%\n",
      "['should', 'always', 'know'] - [when] vs [when]\n",
      "Iter= 45000, Average Loss= 0.474690, Average Accuracy= 90.70%\n",
      "['her', '.', 'i'] - [venture] vs [venture]\n",
      "Iter= 46000, Average Loss= 0.595495, Average Accuracy= 88.20%\n",
      "['of', 'her', 'approach'] - [,] vs [,]\n",
      "Iter= 47000, Average Loss= 0.465039, Average Accuracy= 87.50%\n",
      "['and', 'treacherous', 'manner'] - [in] vs [in]\n",
      "Iter= 48000, Average Loss= 0.446129, Average Accuracy= 89.30%\n",
      "['said', 'he', ','] - [that] vs [and]\n",
      "Iter= 49000, Average Loss= 0.580099, Average Accuracy= 86.00%\n",
      "['meet', 'the', 'case'] - [.] vs [.]\n",
      "Iter= 50000, Average Loss= 0.387768, Average Accuracy= 90.30%\n",
      "['and', 'said', 'he'] - [had] vs [had]\n",
      "Optimization Finished!\n",
      "Elapsed time:  24.646564197540282 min\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=/tmp/tensorflow/rnn_words\n",
      "Point your web browser to: http://localhost:6006/\n",
      "3 words: cat bat bowl\n",
      "Word not in dictionary\n",
      "3 words: cat alice long\n",
      "Word not in dictionary\n",
      "3 words: cat long ago\n",
      "cat long ago last they could take to outwit what measures could take to outwit what measures could take to outwit what measures could take to outwit what measures could take to outwit what measures\n",
      "3 words: long time ago\n",
      "Word not in dictionary\n",
      "3 words: mice general council\n",
      "mice general council and consider what measures could take to outwit what measures could take to outwit what measures could take to outwit what measures could take to outwit what measures could take to outwit\n",
      "3 words: mice cat ago\n",
      "mice cat ago to make what measures enemy , the cat . by this means we should always know when when when when when when when when when when when when when when when when\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-50b72092acbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s words: \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running the graph\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0,n_input+1)\n",
    "    end_offset = n_input + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        if offset > (len(train_data) - end_offset):\n",
    "             offset = random.randint(0, n_input+1)\n",
    "        symbols_in_keys = [ [dictionary[ str(train_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(train_data[offset+n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [train_data[i] for i in range(offset, offset + n_input)]\n",
    "            symbols_out = train_data[offset + n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (n_input+1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    \n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(32):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
